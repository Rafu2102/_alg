# ğŸ æ¼”ç®—æ³•æœŸæœ«å ±å‘Šï¼šå¼·åŒ–å­¸ç¿’è²ªåƒè›‡ AI

> **èª²ç¨‹**ï¼šæ¼”ç®—æ³•  
> **ä½œè€…**ï¼š[æ—æ˜æ˜Œ With Claude Opus 4.5ã€Gemini 3Pro]  
> **æ—¥æœŸ**ï¼š2026-01-02  

---

##[èˆ‡AIçš„å°è©±ç´€éŒ„](https://gemini.google.com/share/a91f66be0118)

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆä½¿ç”¨ **å¼·åŒ–å­¸ç¿’ (Reinforcement Learning)** è¨“ç·´ä¸€å€‹èƒ½è‡ªå‹•éŠç©è²ªåƒè›‡éŠæˆ²çš„ AIã€‚é€é **PPO (Proximal Policy Optimization)** æ¼”ç®—æ³•ï¼Œè®“ AI å­¸æœƒå¦‚ä½•åœ¨ 20x20 çš„ç¶²æ ¼ä¸­ç”Ÿå­˜ã€åƒé£Ÿç‰©ã€ä¸¦ç›¡å¯èƒ½æˆé•·åˆ°æœ€å¤§é•·åº¦ (ç†è«–æ¥µé™ 400)ã€‚

### ğŸ¯ ç›®æ¨™
- è¨“ç·´ AI é”åˆ°æ¥è¿‘**æ»¿åˆ† 400** çš„è¡¨ç¾
- å­¸ç¿’ä¸¦æ‡‰ç”¨å¤šç¨®æ¼”ç®—æ³•æ¦‚å¿µ
- ç†è§£ AI è¨“ç·´éç¨‹ä¸­çš„æŒ‘æˆ°èˆ‡å„ªåŒ–ç­–ç•¥

---

## ğŸ§  ä½¿ç”¨çš„æ¼”ç®—æ³•æ¦‚å¿µ

### 1. å¼·åŒ–å­¸ç¿’ (Reinforcement Learning)
| æ¦‚å¿µ | èªªæ˜ |
|------|------|
| **ç‹€æ…‹ (State)** | 26 ç¶­å‘é‡ï¼ŒåŒ…å«è›‡çš„ä½ç½®ã€é£Ÿç‰©æ–¹å‘ã€å±éšªåµæ¸¬ç­‰ |
| **å‹•ä½œ (Action)** | ä¸Šã€ä¸‹ã€å·¦ã€å³ 4 å€‹é›¢æ•£å‹•ä½œ |
| **çå‹µ (Reward)** | åƒé£Ÿç‰© +1~+50ã€æ­»äº¡ -10ã€æ¯æ­¥ -0.001 |
| **ç­–ç•¥ (Policy)** | ç¥ç¶“ç¶²è·¯è¼¸å‡ºçš„å‹•ä½œæ©Ÿç‡åˆ†ä½ˆ |

### 2. PPO æ¼”ç®—æ³•
- **å„ªå‹¢**: ç©©å®šã€æ¨£æœ¬æ•ˆç‡é«˜ã€é©åˆé€£çºŒè¨“ç·´
- **æ ¸å¿ƒæ©Ÿåˆ¶**: Clipped Objective é˜²æ­¢ç­–ç•¥æ›´æ–°éå¤§
- **å‰µæ–°é»**: ä½¿ç”¨ GAE (Generalized Advantage Estimation) ä¼°è¨ˆå„ªå‹¢å‡½æ•¸

### 3. åœ–è«–èˆ‡æœå°‹æ¼”ç®—æ³•
| æ¼”ç®—æ³• | æ‡‰ç”¨å ´æ™¯ |
|--------|---------|
| **BFS (å»£åº¦å„ªå…ˆæœå°‹)** | è¨ˆç®—å¯é”å€åŸŸã€åˆ¤æ–·æ˜¯å¦æœƒå›°ä½è‡ªå·± |
| **Flood Fill** | è©•ä¼°æ¯å€‹æ–¹å‘çš„ç©ºé–“å¤§å° |
| **Hamiltonian Cycle** | Autopilot æ¨¡å¼çš„å®‰å…¨è·¯å¾‘ç”Ÿæˆ |
| **A\* æœå°‹** | è·¯å¾‘è¦åŠƒå„ªåŒ– |

### 4. å‹•æ…‹è¦åŠƒæ¦‚å¿µ
- ä½¿ç”¨ **Temporal Difference** æ›´æ–°åƒ¹å€¼å‡½æ•¸
- **æŠ˜æ‰£å› å­ Î³ = 0.99**ï¼šå¹³è¡¡çŸ­æœŸèˆ‡é•·æœŸçå‹µ

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
ğŸ“¦ è²ªåƒè›‡V10.0/
â”œâ”€â”€ ğŸ“„ train_v10.py       # è¨“ç·´è…³æœ¬ (PPO + Curriculum Learning)
â”œâ”€â”€ ğŸ“„ snake_env_v10.py   # éŠæˆ²ç’°å¢ƒ (Gym API)
â”œâ”€â”€ ğŸ“„ snake_utils_v10.py # è¼”åŠ©å‡½æ•¸ (BFS, Flood Fill)
â”œâ”€â”€ ğŸ“„ watch_v10.py       # è¦–è¦ºåŒ–èˆ‡ Autopilot
â”œâ”€â”€ ğŸ“„ monitor.py         # è¨“ç·´ç›£æ§
â”œâ”€â”€ ğŸ“‚ checkpoints/       # æ¨¡å‹å­˜æª”é»
â””â”€â”€ ğŸ“‚ snake_v10_logs/    # è¨“ç·´æ—¥èªŒ (TensorBoard)
```

---

## ğŸš€ ç‰ˆæœ¬æ¼”é€²æ­·ç¨‹

æœ¬å°ˆæ¡ˆç¶“æ­·äº†å¤šæ¬¡è¿­ä»£å„ªåŒ–ï¼Œæ¯æ¬¡å¤±æ•—éƒ½å¸¶ä¾†å¯¶è²´çš„æ•™è¨“ï¼š

| ç‰ˆæœ¬ | æœ€ä½³æˆç¸¾ | ç‹€æ…‹ | ä¸»è¦ç‰¹é» |
|------|---------|------|---------|
| V6.0 | **375** | âœ… æˆåŠŸ | 26 ç¶­ obs, 256Ã—256 ç¶²è·¯ |
| V7.0 | 217 | âŒ å¤±æ•— | ç¶²è·¯éå¤§ (512Ã—512) |
| V9.0 | 229 | âŒ å¤±æ•— | 96 ç¶­ obs ä¿¡è™Ÿç¨€é‡‹ |
| V10.0 | ç›®æ¨™ 400 | ğŸ”„ é€²è¡Œä¸­ | å›æ­¸ V6.0 æ ¸å¿ƒ + å„ªåŒ– |

### å¤±æ•—ä¸­å­¸åˆ°çš„æ•™è¨“
1. **è¶Šè¤‡é›œä¸ä»£è¡¨è¶Šå¥½**ï¼š96 ç¶­è§€å¯Ÿç©ºé–“åè€Œé™ä½æ•ˆèƒ½
2. **éæ“¬åˆæ˜¯å¤§æ•µ**ï¼šN_EPOCHS éé«˜å°è‡´å­¸ç¿’åœæ»¯
3. **èª²ç¨‹å­¸ç¿’å¾ˆé‡è¦**ï¼šå¾ªåºæ¼¸é€²çš„è¨“ç·´æ¯”ä¸€æ¬¡åˆ°ä½æ›´æœ‰æ•ˆ

---

## ğŸ® æ ¸å¿ƒåŠŸèƒ½å±•ç¤º

### è¨“ç·´æµç¨‹ (Curriculum Learning)
```
Stage A (30M æ­¥) â†’ Stage B (70M æ­¥) â†’ Stage C (100M æ­¥)
    åŸºç¤å­¸ç¿’          Endgame è¨“ç·´        æœ€çµ‚è¡åˆº
```

### è§€å¯Ÿç©ºé–“è¨­è¨ˆ (26 ç¶­)
```
[0-3]   å››æ–¹å‘å±éšªåµæ¸¬
[4-7]   é£Ÿç‰©ç›¸å°æ–¹å‘
[8-11]  Flood Fill é¢ç©
[12-15] BFS å¯é”æ€§
[16-25] é€²éšç‰¹å¾µ
```

### Autopilot æ¨¡å¼
ä½¿ç”¨ **Hamiltonian Cycle** ç¢ºä¿ 100% å®‰å…¨çš„è·¯å¾‘ï¼Œçµåˆ **å‹•æ…‹æ·å¾‘** åŠ é€ŸéŠæˆ²é€²ç¨‹ã€‚

---

## ğŸ“Š é—œéµç¨‹å¼ç¢¼ç‰‡æ®µ

### çå‹µå‡½æ•¸è¨­è¨ˆ
```python
def calculate_reward(snake_length, ate_food, died):
    if died:
        return -10.0
    if ate_food:
        # Sigmoid æ¼¸æ¸›çå‹µ
        return 1.0 + 49.0 * (1 - snake_length / 400)
    return -0.001  # æ¯æ­¥å°æ‡²ç½°ä¿ƒé€²æ•ˆç‡
```

### BFS å¯é”æ€§æª¢æ¸¬
```python
def bfs_reachable(grid, start, target):
    """ä½¿ç”¨ BFS åˆ¤æ–·å¾ start èƒ½å¦åˆ°é” target"""
    queue = deque([start])
    visited = {start}
    while queue:
        pos = queue.popleft()
        if pos == target:
            return True
        for neighbor in get_neighbors(pos):
            if neighbor not in visited and grid[neighbor] == 0:
                visited.add(neighbor)
                queue.append(neighbor)
    return False
```

---

## ğŸ”§ å¦‚ä½•åŸ·è¡Œ

### ç’°å¢ƒéœ€æ±‚
```bash
pip install stable-baselines3 gymnasium pygame numpy
```

### è¨“ç·´æ¨¡å‹
```bash
python train_v10.py
```

### è§€çœ‹ AI éŠç©
```bash
python watch_v10.py
```

### ç›£æ§è¨“ç·´
```bash
tensorboard --logdir=snake_v10_logs
```

---

## ğŸ“ˆ å­¸ç¿’æˆæœ

é€éé€™å€‹å°ˆæ¡ˆï¼Œæˆ‘å­¸åˆ°äº†ï¼š

1. **æ¼”ç®—æ³•æ‡‰ç”¨**ï¼šå¦‚ä½•å°‡ BFSã€Flood Fill æ‡‰ç”¨æ–¼å¯¦éš›å•é¡Œ
2. **æ©Ÿå™¨å­¸ç¿’èª¿åƒ**ï¼šå­¸ç¿’ç‡ã€ç¶²è·¯æ¶æ§‹ã€çå‹µè¨­è¨ˆçš„å¹³è¡¡
3. **å¤±æ•—åˆ†æ**ï¼šå¾å¤±æ•—ç‰ˆæœ¬ä¸­æå–ç¶“é©—æ•™è¨“
4. **å·¥ç¨‹å¯¦è¸**ï¼šç‰ˆæœ¬æ§åˆ¶ã€å¯¦é©—è¨˜éŒ„ã€è¦–è¦ºåŒ–ç›£æ§

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [Stable Baselines3 Documentation](https://stable-baselines3.readthedocs.io/)
- [OpenAI Spinning Up - PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)
- [Gymnasium Documentation](https://gymnasium.farama.org/)

*æ­¤å ±å‘Šä½œç‚ºæ¼”ç®—æ³•èª²ç¨‹æœŸæœ«ä½œå“ï¼Œå±•ç¤ºå¼·åŒ–å­¸ç¿’èˆ‡å‚³çµ±æ¼”ç®—æ³•çš„çµåˆæ‡‰ç”¨ã€‚*
